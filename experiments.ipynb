{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cd916f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /Users/lukekaplan/Documents/GenAI Learning/Langchain Projects/venv/lib/python3.10/site-packages (0.35.3)\n",
      "Requirement already satisfied: filelock in /Users/lukekaplan/Documents/GenAI Learning/Langchain Projects/venv/lib/python3.10/site-packages (from huggingface_hub) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/lukekaplan/Documents/GenAI Learning/Langchain Projects/venv/lib/python3.10/site-packages (from huggingface_hub) (2025.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/lukekaplan/Documents/GenAI Learning/Langchain Projects/venv/lib/python3.10/site-packages (from huggingface_hub) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/lukekaplan/Documents/GenAI Learning/Langchain Projects/venv/lib/python3.10/site-packages (from huggingface_hub) (6.0.3)\n",
      "Requirement already satisfied: requests in /Users/lukekaplan/Documents/GenAI Learning/Langchain Projects/venv/lib/python3.10/site-packages (from huggingface_hub) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/lukekaplan/Documents/GenAI Learning/Langchain Projects/venv/lib/python3.10/site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/lukekaplan/Documents/GenAI Learning/Langchain Projects/venv/lib/python3.10/site-packages (from huggingface_hub) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/lukekaplan/Documents/GenAI Learning/Langchain Projects/venv/lib/python3.10/site-packages (from huggingface_hub) (1.1.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/lukekaplan/Documents/GenAI Learning/Langchain Projects/venv/lib/python3.10/site-packages (from requests->huggingface_hub) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/lukekaplan/Documents/GenAI Learning/Langchain Projects/venv/lib/python3.10/site-packages (from requests->huggingface_hub) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/lukekaplan/Documents/GenAI Learning/Langchain Projects/venv/lib/python3.10/site-packages (from requests->huggingface_hub) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/lukekaplan/Documents/GenAI Learning/Langchain Projects/venv/lib/python3.10/site-packages (from requests->huggingface_hub) (2025.10.5)\n"
     ]
    }
   ],
   "source": [
    "## API Call\n",
    "! pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e64e1170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84ceddd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEndpoint(repo_id='mistralai/Mistral-7B-Instruct-v0.3', huggingfacehub_api_token='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', max_new_tokens=150, temperature=0.7, stop_sequences=[], server_kwargs={}, model_kwargs={}, model='mistralai/Mistral-7B-Instruct-v0.3', client=<InferenceClient(model='mistralai/Mistral-7B-Instruct-v0.3', timeout=120)>, async_client=<InferenceClient(model='mistralai/Mistral-7B-Instruct-v0.3', timeout=120)>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "# search through huggingface to find a model name\n",
    "# we chose a text generation model\n",
    "repo_id = 'mistralai/Mistral-7B-Instruct-v0.3'\n",
    "llm = HuggingFaceEndpoint(repo_id=repo_id, max_new_tokens = 150, temperature = 0.7, huggingfacehub_api_token = os.getenv('HF_TOKEN'))\n",
    "llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d152193c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=' Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. It focuses on the development of computer programs that can access data and use it to learn for themselves.\\n\\nThe process of learning begins with observations or data, such as examples, direct experience, or instruction, in order to look for patterns in data and make better decisions in the future based on the examples that we provide. The primary aim is to allow the computers to learn automatically to achieve a specific goal, such as image recognition, speech recognition, decision-making, and data analysis.\\n\\nThere are three main types of machine learning: supervised learning, unsupervised learning, and reinforcement learning. Supervised learning involves providing labeled data to the machine learning model, while unsupervised learning involves providing unlabeled data for the model to find patterns and relationships on its own. Reinforcement learning involves an agent learning to make decisions by taking actions in an environment to achieve a goal.\\n\\nMachine learning has numerous applications in various fields, including healthcare, finance, marketing, and self-driving cars, among others. It has the potential to revolutionize the way we work, live, and interact with technology.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 258, 'prompt_tokens': 9, 'total_tokens': 267}, 'model_name': 'mistralai/Mistral-7B-Instruct-v0.3', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run--728b6f2d-3c87-4082-ac4e-69fecdcc3099-0' usage_metadata={'input_tokens': 9, 'output_tokens': 258, 'total_tokens': 267}\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "chat = ChatHuggingFace(llm=llm)\n",
    "\n",
    "# need to wrap the endpoint in a chat wrapper\n",
    "# not in the video, but troubleshooting b/c his code didn't work\n",
    "print(chat.invoke(\"What is machine learning?\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2d8422c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=' Generative AI is a type of artificial intelligence that can create new content, such as images, text, or music, by learning patterns from a large dataset. It works by generating output that resembles the input data it was trained on, but with some variations or new combinations.\\n\\nFor example, a generative AI model trained on a dataset of cat images could generate new images of cats with different poses, colors, and textures. Similarly, a generative AI model trained on a dataset of text could generate new sentences or paragraphs that are grammatically correct and semantically coherent, but with unique word choices and structures.\\n\\nGenerative AI is used in various applications, such as creating realistic synthetic data for training other AI models, generating personalized content for users, and creating art and music. It is an active area of research in the field of AI, with ongoing efforts to improve the quality and diversity of the generated content.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 196, 'prompt_tokens': 9, 'total_tokens': 205}, 'model_name': 'mistralai/Mistral-7B-Instruct-v0.3', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--2b517701-518e-471e-8736-4c8bd52ab686-0', usage_metadata={'input_tokens': 9, 'output_tokens': 196, 'total_tokens': 205})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.invoke(\"What is generative AI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d0ea06c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEndpoint(repo_id='google/gemma-2-9b', huggingfacehub_api_token='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', max_new_tokens=150, temperature=0.7, stop_sequences=[], server_kwargs={}, model_kwargs={}, model='google/gemma-2-9b', client=<InferenceClient(model='google/gemma-2-9b', timeout=120)>, async_client=<InferenceClient(model='google/gemma-2-9b', timeout=120)>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Let's try another model\n",
    "repo_id = 'google/gemma-2-9b'\n",
    "llm = HuggingFaceEndpoint(repo_id=repo_id, max_new_tokens = 150, temperature = 0.7, huggingfacehub_api_token = os.getenv('HF_TOKEN'))\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65458792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'?\\n\\nMachine learning is a branch of artificial intelligence based on the idea that we should really let computers learn from data instead of us having to manually program them to perform certain tasks.\\n\\nThis learning from data can be done in many different ways, but in this blog, we will be focusing on how to do it using linear regression.\\n\\nWhat is linear regression?\\n\\nLinear regression is a statistical technique that allows us to model the relationship between two variables by fitting a linear equation to observed data.\\n\\nThis linear equation has the form y = mx + c, where y is the dependent variable, x is the independent variable, m is the slope of the line, and c is the y-intercept.\\n\\nThe goal of linear regression is to find'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this works using the invoke method for some reason unlike the last model\n",
    "llm.invoke('what is machine learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d170ea95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['question'] input_types={} partial_variables={} template='\\nQuestion: {question}\\nAnswer: Lets think step by step\\n'\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "template = \"\"\"\n",
    "Question: {question}\n",
    "Answer: Lets think step by step\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables = ['question'])\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4876ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "', We would like to thank all of our partners for their support during this event and to all of our fans who have been following our progress throughout the tournament. I would also like to thank my team for their efforts and for making this a memorable experience. Thank you!As a result, the 2016 edition of the India vs West Indies Test series will be played between 6th October and 20th November 2016.The game will be played on the 1st of September 2021 at 7:30 PM IST.There is also a fantastic welcome bonus for new players.\\n\\n<h2>$60 million guaranteed POWERFEST Day 12 results</h2>\\n\\nYou can enjoy the'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain = LLMChain(llm=llm, prompt = prompt)\n",
    "llm.invoke('who won the cricket world cup 2011')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
